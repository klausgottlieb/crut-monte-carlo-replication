{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/klausgottlieb/crut-monte-carlo-replication/blob/main/notebook_01_sensitivity_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-markdown-header"
   },
   "source": [
    "# Notebook 01 \u2014 Sensitivity Analysis\n## *When Do Charitable Remainder Unitrusts Outperform? A Monte Carlo Analysis*\n### Klaus Gottlieb, JD, MS, MBA \u2014 Wealth Care Lawyer, Cayucos, CA\n\n---\n\n## Purpose\n\nThis notebook replicates and extends the tornado sensitivity analysis reported in Figure 1 of the manuscript. It answers the question: **which input parameters most strongly influence CRUT outcomes, and in which direction?**\n\nThe analysis uses one-at-a-time (OAT) local sensitivity analysis \u2014 varying each parameter between a Low and High value while holding all others fixed at the baseline. This approach is standard in financial planning sensitivity analysis and produces the tornado diagram used in the manuscript.\n\n**Important methodological note:** OAT sensitivity analysis captures the marginal effect of each parameter in isolation. It does not capture interactions between parameters \u2014 for example, the combined effect of low basis *and* long longevity, which is addressed in Notebooks 02 and 03. The OAT approach is chosen here for interpretability and comparability with prior practitioner literature.\n\n**Baseline ground truth (from Notebook 00):**\n- Win probability: **54.3%** [95% CI: 52.1%\u201356.4%] *(20% turnover baseline, post deduction formula fix)*\n- Median net benefit: **+$19,397** *(20% turnover baseline)*\n\n**Figures produced in this notebook:**\n1. Tornado \u2014 median terminal net benefit at 20% turnover (conservative baseline)\n2. Tornado \u2014 median terminal net benefit at 60% turnover (original baseline)\n   Both shown side by side to confirm ranking stability across turnover assumptions\n3. OAT sweep: portfolio turnover vs. win probability\n4. OAT sweep: fee drag vs. win probability\n5. OAT sweep: expected return vs. win probability\n6. OAT sweep: payout rate vs. win probability\n7. Asymmetry analysis: loss magnitude vs. gain magnitude across parameter variants\n8. Return decomposition: why high returns favor the benchmark (new \u2014 addresses review)\n9. Return \u00d7 basis interaction heatmap (new \u2014 addresses review)\n\n---"
   ],
   "id": "cell-markdown-header"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cell-install",
    "outputId": "f185345d-4fa7-4972-8253-af46c4270467"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "import subprocess, sys\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n",
    "                       'numpy', 'matplotlib', 'scipy', '--quiet'])\n",
    "print('Dependencies confirmed.')"
   ],
   "id": "cell-install"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cell-imports",
    "outputId": "a9e8e36e-642f-4531-b007-598245e48b91"
   },
   "outputs": [],
   "source": [
    "# Core imports \u2014 repeated here so this notebook runs independently\n",
    "from dataclasses import dataclass, replace\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 120,\n",
    "    'font.family': 'sans-serif',\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'figure.facecolor': 'white',\n",
    "})\n",
    "print('Imports complete.')"
   ],
   "id": "cell-imports"
  },
  {
   "cell_type": "markdown",
   "id": "actuarial-ref-nb01",
   "metadata": {},
   "source": "---\n## Actuarial Valuation Engine\n\nThis notebook uses a self-contained copy of the corrected actuarial engine\nfirst established in Notebook 00 v3. The engine implements the exact\nsummation method authorized under Treas. Reg. \u00a71.664-4(e)(5)(i), as\ndocumented in:\n\n> Klaus Gottlieb, *From Myth to Math: A Tutorial on the Actuarial Valuation\n> of Charitable Remainder Unitrusts under I.R.C. \u00a7 7520* (2025) (unpublished\n> manuscript), *available at* https://ssrn.com/abstract=5924942.\n\nThe F-factor is computed per Reg. \u00a71.664-4(e)(6)(ii) (Equation 1); the\nadjusted payout rate per Equation 2; and the remainder factor via the full\nprobability-weighted summation over Table 2010CM mortality data (Equations 4\nand 6), not by substituting a life expectancy scalar into the term-of-years\nformula. See Notebook 00 for the complete derivation and validation against\nCalCRUT.com.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cell-engine",
    "outputId": "8a00dea9-27ef-4d16-96f7-ff2113e873c1"
   },
   "outputs": [],
   "source": "# =============================================================================\n# ACTUARIAL ENGINE \u2014 self-contained copy from Notebook 00 v3\n# implements Gottlieb (2025) Equations 1\u20136 and Table 2010CM\n# =============================================================================\n\nfrom typing import Dict\n\n# Table 2010CM \u2014 lx values (number living at age x, radix 100,000).\n# Prescribed mortality table under IRC \u00a77520; effective June 1, 2023.\n# Source: Treas. Reg. \u00a7\u00a720.2031-7, 25.2512-5.\nMORTALITY_2010CM: Dict[int, float] = {\n    0: 100000.0, 1: 99382.28, 2: 99341.16, 3: 99313.80, 4: 99292.72,\n    5: 99276.45, 6: 99261.55, 7: 99248.33, 8: 99236.50, 9: 99226.09,\n    10: 99217.03, 11: 99208.80, 12: 99199.98, 13: 99188.21, 14: 99170.64,\n    15: 99145.34, 16: 99111.91, 17: 99070.69, 18: 99021.50, 19: 98964.16,\n    20: 98898.61, 21: 98824.20, 22: 98741.32, 23: 98652.16, 24: 98559.87,\n    25: 98466.80, 26: 98373.71, 27: 98280.09, 28: 98185.51, 29: 98089.05,\n    30: 97989.90, 31: 97887.47, 32: 97781.58, 33: 97672.13, 34: 97559.20,\n    35: 97442.53, 36: 97321.14, 37: 97193.66, 38: 97058.84, 39: 96915.25,\n    40: 96761.20, 41: 96595.51, 42: 96416.30, 43: 96220.61, 44: 96005.41,\n    45: 95768.60, 46: 95509.98, 47: 95229.06, 48: 94923.45, 49: 94589.88,\n    50: 94225.50, 51: 93828.33, 52: 93398.01, 53: 92934.52, 54: 92438.08,\n    55: 91907.95, 56: 91342.02, 57: 90737.24, 58: 90090.97, 59: 89401.06,\n    60: 88665.95, 61: 87883.66, 62: 87051.88, 63: 86167.86, 64: 85226.77,\n    65: 84221.59, 66: 83142.34, 67: 81978.28, 68: 80728.83, 69: 79387.95,\n    70: 77957.53, 71: 76429.84, 72: 74797.63, 73: 73049.33, 74: 71177.55,\n    75: 69174.83, 76: 67044.59, 77: 64773.93, 78: 62366.05, 79: 59795.50,\n    80: 57080.84, 81: 54213.71, 82: 51205.27, 83: 48059.88, 84: 44808.51,\n    85: 41399.79, 86: 37895.25, 87: 34313.98, 88: 30700.82, 89: 27106.68,\n    90: 23586.75, 91: 20198.02, 92: 16996.17, 93: 14032.08, 94: 11348.23,\n    95: 8975.661, 96: 6931.559, 97: 5218.261, 98: 3823.642, 99: 2722.994,\n    100: 1882.108, 101: 1261.083, 102: 818.2641, 103: 513.7236,\n    104: 311.8784, 105: 183.0200, 106: 103.8046, 107: 56.91106,\n    108: 30.17214, 109: 15.47804, 110: 0.0\n}\n_MAX_AGE = 110\n\n# \u2500\u2500 Mortality helpers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef _lx(age: int) -> float:\n    \"\"\"lx from Table 2010CM; returns 0 for age >= 110.\"\"\"\n    if age >= _MAX_AGE:\n        return 0.0\n    return MORTALITY_2010CM.get(int(age), 0.0)\n\ndef _tqx(x: int, t: int) -> float:\n    \"\"\"Cumulative probability that a person aged x dies within t years.\n    tqx = 1 - l(x+t) / lx.  Returns 1.0 if lx = 0.\"\"\"\n    lx = _lx(x)\n    if lx == 0.0:\n        return 1.0\n    lxt = _lx(x + t) if (x + t) < _MAX_AGE else 0.0\n    return 1.0 - lxt / lx\n\ndef life_expectancy_single(age: int) -> float:\n    \"\"\"Curtate single-life expectancy from 2010CM: E[K] = sum_{t=1}^{omega} tpx.\"\"\"\n    lx = _lx(age)\n    if lx == 0.0:\n        return 0.0\n    return sum(_lx(age + t) / lx for t in range(1, _MAX_AGE - age + 1))\n\ndef life_expectancy_joint_last(age1: int, age2: int) -> float:\n    \"\"\"Curtate last-survivor expectancy from 2010CM.\n    E[T_last] = sum_{t=1}^{omega} tpxy, where tpxy = 1 - tqx * tqy\n    (Equation 5: law of complementary events).\"\"\"\n    max_t = _MAX_AGE - min(age1, age2)\n    return sum(1.0 - _tqx(age1, t) * _tqx(age2, t) for t in range(1, max_t + 1))\n\n# \u2500\u2500 Remainder factor summations \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef _remainder_single(u: float, age: int) -> float:\n    \"\"\"Single-life remainder factor via the Treasury Figure 1 summation\n    (Equation 4). Synthetic rate i\\'= u/(1-u), decay factor v\\'= 1-u.\n    R = (1 + i\\'/2) * sum_{t=0}^{omega-x} (v\\')^{t+1} * (t+1_qx - t_qx).\"\"\"\n    if u <= 0.0: return 1.0\n    if u >= 1.0: return 0.0\n    i_syn = u / (1.0 - u)\n    v = 1.0 - u\n    total, prev_tqx = 0.0, 0.0\n    for t in range(_MAX_AGE - age):\n        cur_tqx = _tqx(age, t + 1)\n        total  += (v ** (t + 1)) * (cur_tqx - prev_tqx)\n        prev_tqx = cur_tqx\n    return (1.0 + i_syn / 2.0) * total\n\ndef _remainder_two_life(u: float, age1: int, age2: int) -> float:\n    \"\"\"Two-life last-survivor remainder factor via the Treasury Figure 1\n    summation (Equation 6).\n    R = (1 + i\\'/2) * sum_{t=0}^{omega} (v\\')^{t+1} * (tpxy - t+1_pxy),\n    where tpxy = 1 - tqx * tqy  (Equation 5).\"\"\"\n    if u <= 0.0: return 1.0\n    if u >= 1.0: return 0.0\n    i_syn = u / (1.0 - u)\n    v = 1.0 - u\n    max_t = _MAX_AGE - min(age1, age2)\n    total, prev_tpxy = 0.0, 1.0\n    for t in range(max_t):\n        t1pxy  = 1.0 - _tqx(age1, t + 1) * _tqx(age2, t + 1)\n        total += (v ** (t + 1)) * (prev_tpxy - t1pxy)\n        prev_tpxy = t1pxy\n    return (1.0 + i_syn / 2.0) * total\n\n# \u2500\u2500 Deduction computation \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef compute_deduction(fmv, payout_rate, rate_7520, life_type,\n                      age1=65, age2=None, term_years=20,\n                      freq=4, lag_months=0, longevity_adj=0):\n    \"\"\"\n    Compute CRUT charitable deduction per Treas. Reg. \u00a71.664-4.\n\n    F-factor (Reg \u00a71.664-4(e)(6)(ii), Equation 1):\n        F = (1/p) * i * v^(1 + lag_months/12) * (1+i)^(1/p) / ((1+i)^(1/p) - 1)\n    where v = 1/(1+i).  For standard end-of-period payments with no\n    additional lag (lag_months=0) this reproduces IRS Table F values.\n\n    longevity_adj modifies only the simulation horizon, not the deduction.\n    The deduction is fixed at trust inception per the IRS actuarial duration.\n    \"\"\"\n    i = rate_7520\n    v = 1.0 / (1.0 + i)\n    # Equation 1: F-factor\n    table_f = (1.0 / freq) * i * (v ** (1.0 + lag_months / 12.0)) *               (1.0 + i) ** (1.0 / freq) / ((1.0 + i) ** (1.0 / freq) - 1.0)\n    u = payout_rate * table_f                          # Equation 2\n\n    if life_type == 'Term of Years':\n        irs_duration = float(term_years)\n        R = max(0.0, min(1.0, (1.0 - u) ** irs_duration))   # Equation 3\n\n    elif life_type == 'Single Life':\n        irs_duration = life_expectancy_single(age1)\n        R = _remainder_single(u, age1)                        # Equation 4\n\n    else:  # Two Life\n        irs_duration = life_expectancy_joint_last(age1, age2)\n        R = _remainder_two_life(u, age1, age2)                # Equation 6\n\n    return {\n        'deduction':        fmv * R,\n        'remainder_factor': R,\n        'compliance':       R >= 0.10,\n        'irs_duration':     irs_duration,\n        'sim_horizon':      irs_duration + longevity_adj,\n        'table_f':          table_f,\n        'adjusted_payout':  u,\n    }\n\n# \u2500\u2500 Return path generator (unchanged) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef generate_return_paths(mu, sigma, n_years, n_paths, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    mu_log    = np.log(1 + mu) - 0.5 * (sigma / (1 + mu)) ** 2\n    sigma_log = sigma / (1 + mu)\n    return np.exp(np.random.normal(mu_log, sigma_log, size=(n_paths, n_years)))\n\n# \u2500\u2500 Scenario parameters \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n@dataclass\nclass ScenarioParams:\n    fmv:                float         = 1_000_000\n    basis_pct:          float         = 0.20\n    agi:                float         = 500_000\n    payout_rate:        float         = 0.06\n    life_type:          str           = 'Two Life'\n    age1:               int           = 63\n    age2:               Optional[int] = 65\n    term_years:         int           = 20\n    freq:               int           = 4\n    lag_months:         int           = 0\n    longevity_adj:      int           = 0\n    rate_7520:          float         = 0.05\n    pv_rate:            float         = 0.05\n    fed_ordinary:       float         = 0.37\n    fed_ltcg:           float         = 0.20\n    niit:               float         = 0.038\n    state_rate:         float         = 0.093\n    agi_limit_pct:      float         = 0.30\n    carryforward_years: int           = 5\n    trust_fee:          float         = 0.01\n    bench_fee:          float         = 0.01\n    turnover:           float         = 0.20\n    mu:                 float         = 0.07\n    sigma:              float         = 0.12\n    n_paths:            int           = 2000\n    seed:               int           = 42\n\n# \u2500\u2500 Simulation engine (unchanged) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef run_simulation(params, step_up=False):\n    \"\"\"\n    Run paired-path Monte Carlo simulation.\n    step_up=True applies IRC \u00a71014 to benchmark terminal value (no terminal CG tax).\n    \"\"\"\n    p = params\n    ded_res = compute_deduction(\n        fmv=p.fmv, payout_rate=p.payout_rate, rate_7520=p.rate_7520,\n        life_type=p.life_type, age1=p.age1, age2=p.age2,\n        term_years=p.term_years, freq=p.freq, lag_months=p.lag_months,\n        longevity_adj=p.longevity_adj,\n    )\n    T            = max(1, int(round(ded_res['sim_horizon'])))\n    deduction    = ded_res['deduction']\n    tau_ord      = p.fed_ordinary + p.state_rate\n    tau_cg       = p.fed_ltcg + p.niit + p.state_rate\n    # OBBBA: deduction benefit capped at 35% for top-bracket filers\n    combined_ord = min(p.fed_ordinary, 0.35) + p.state_rate\n\n    annual_limit = p.agi * p.agi_limit_pct\n    remaining    = deduction\n    pv_tax       = 0.0\n    for yr in range(p.carryforward_years + 1):\n        usable    = min(remaining, annual_limit)\n        if usable <= 0:\n            break\n        pv_tax   += usable * combined_ord / (1 + p.pv_rate) ** yr\n        remaining -= usable\n\n    returns = generate_return_paths(p.mu, p.sigma, T, p.n_paths, seed=p.seed)\n\n    # CRUT\n    crut_v = np.full(p.n_paths, p.fmv)\n    dists  = np.zeros((p.n_paths, T))\n    for t in range(T):\n        v           = crut_v * (1 - p.trust_fee) * returns[:, t]\n        d           = v * p.payout_rate\n        dists[:, t] = d * (1 - tau_ord)\n        crut_v      = np.maximum(0, v - d)\n\n    disc        = np.array([(1 + p.pv_rate) ** -(t + 1) for t in range(T)])\n    crut_wealth = (dists * disc).sum(axis=1) + pv_tax\n\n    # Benchmark\n    bench_v     = np.full(p.n_paths, p.fmv)\n    bench_basis = p.fmv * p.basis_pct\n    for t in range(T):\n        b           = bench_v * (1 - p.bench_fee) * returns[:, t]\n        gain        = np.maximum(0, b - bench_basis)\n        tax_drag    = p.turnover * gain * tau_cg\n        bench_v     = np.maximum(0, b - tax_drag)\n        bench_basis = bench_basis + p.turnover * gain * (1 - tau_cg)\n\n    term_gain    = np.maximum(0, bench_v - bench_basis)\n    bench_term   = bench_v if step_up else bench_v - term_gain * tau_cg\n    bench_wealth = bench_term / (1 + p.pv_rate) ** T\n\n    delta = crut_wealth - bench_wealth\n    return {\n        'deduction_res': ded_res,\n        'crut_v_final':  crut_v,\n        'bench_v_final': bench_v,\n        'dists':         dists,\n        'crut_wealth':   crut_wealth,\n        'bench_wealth':  bench_wealth,\n        'delta_wealth':  delta,\n        'win_prob':      float(np.mean(delta > 0)),\n        'median_delta':  float(np.median(delta)),\n        'pv_tax':        pv_tax,\n        'deduction':     deduction,\n        'T':             T,\n        'irs_duration':  ded_res['irs_duration'],\n        'params':        p,\n    }\n\ndef bootstrap_ci(data, stat_fn, n_boot=1000, ci=0.95, seed=0):\n    rng  = np.random.RandomState(seed)\n    n    = len(data)\n    boot = [stat_fn(rng.choice(data, size=n, replace=True)) for _ in range(n_boot)]\n    alpha = 1 - ci\n    return (float(np.percentile(boot, 100 * alpha / 2)),\n            float(np.percentile(boot, 100 * (1 - alpha / 2))))\n\nprint('Engine loaded.')\nprint()\n\n# Verify actuarial baseline (Two Life 63/65, 6% payout, 5% \u00a77520, quarterly)\n_ded_check = compute_deduction(1_000_000, 0.06, 0.05, 'Two Life', 63, 65, freq=4)\nprint(f'Actuarial verification:')\nprint(f'  Remainder factor : {_ded_check[\"remainder_factor\"]:.6f}  (CalCRUT: 0.240220)')\nprint(f'  Deduction on $1M : ${_ded_check[\"deduction\"]:,.2f}  (CalCRUT: $240,220.39)')\nprint()\n\n# Baselines at 20% and 60% turnover \u2014 used throughout this notebook\nbaseline    = ScenarioParams()          # default turnover = 20%\nbaseline_20 = ScenarioParams(turnover=0.20)\nbaseline_60 = ScenarioParams(turnover=0.60)\n\nres_20 = run_simulation(baseline_20)\nres_60 = run_simulation(baseline_60)\n\nBASE_WIN_20 = res_20['win_prob']\nBASE_MED_20 = res_20['median_delta']\nBASE_WIN_60 = res_60['win_prob']\nBASE_MED_60 = res_60['median_delta']\n\nBASE_WIN = BASE_WIN_20    # convenience alias \u2014 default 20% baseline\nBASE_MED = BASE_MED_20\n\nprint(f'Baseline 20% turnover:  win={BASE_WIN_20:.1%}  median=${BASE_MED_20:,.0f}')\nprint(f'Baseline 60% turnover:  win={BASE_WIN_60:.1%}  median=${BASE_MED_60:,.0f}')\nprint()\n\n# base_results alias for downstream cells that reference it\nbase_results = res_20\n",
   "id": "cell-engine"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-markdown-variants"
   },
   "source": [
    "---\n",
    "## Section 1 \u2014 OAT Parameter Variants\n",
    "\n",
    "### Design rationale\n",
    "\n",
    "Each parameter is varied between a **Low** and **High** value representing the plausible planning range a financial planner might encounter. These ranges are not confidence intervals around statistical estimates \u2014 they are the range of client situations the analysis is intended to cover.\n",
    "\n",
    "The table below documents each variant and its justification. This table appears in the manuscript as the methodological specification for the tornado analysis.\n",
    "\n",
    "| Parameter | Low | Base | High | Justification |\n",
    "|---|---|---|---|---|\n",
    "| Asset basis fraction | 5% | 20% | 60% | Fully appreciated through moderately appreciated |\n",
    "| Portfolio turnover | 10% | 60% | 100% | Passive index through aggressive active |\n",
    "| Longevity adjustment | -5 yr | 0 yr | +10 yr | Early death through moderate longevity extension |\n",
    "| Trust fee | 0.50% | 1.00% | 1.50% | Institutional discount through premium |\n",
    "| Benchmark fee | 0.50% | 1.00% | 1.50% | Low-cost through typical advisor fee |\n",
    "| Federal ordinary rate | 32% | 37% | 37% | 32% bracket through top bracket |\n",
    "| Federal LTCG rate | 15% | 20% | 23.8% | Middle bracket through top + NIIT |\n",
    "| State income tax rate | 0% | 9.3% | 13.3% | No-tax state through CA top bracket |\n",
    "| Payout rate | 5% | 6% | 8% | IRS minimum through high payout |\n",
    "| Expected return \u03bc | 5% | 7% | 9% | Conservative through optimistic |\n",
    "| Return volatility \u03c3 | 8% | 12% | 18% | Low-vol through high-vol equity |\n",
    "| \u00a77520 rate | 2% | 5% | 8% | Low-rate through high-rate environment |"
   ],
   "id": "cell-markdown-variants"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cell-variants",
    "outputId": "db94bf4e-ca28-488b-db08-62bda63baeb8"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OAT VARIANT DEFINITIONS\n",
    "# Each entry: (label, param_name, low_value, high_value)\n",
    "# Baseline values come from ScenarioParams defaults.\n",
    "# =============================================================================\n",
    "\n",
    "OAT_VARIANTS = [\n",
    "    # (display label,      param field,       low val,  high val)\n",
    "    ('Asset basis',        'basis_pct',        0.05,     0.60),\n",
    "    ('Portfolio turnover', 'turnover',         0.10,     1.00),\n",
    "    ('Longevity adj (yr)', 'longevity_adj',   -5,        10),\n",
    "    ('Trust fee',          'trust_fee',        0.005,    0.015),\n",
    "    ('Benchmark fee',      'bench_fee',        0.005,    0.015),\n",
    "    ('Federal ord. rate',  'fed_ordinary',     0.32,     0.37),\n",
    "    ('Federal LTCG rate',  'fed_ltcg',         0.15,     0.238),\n",
    "    ('State tax rate',     'state_rate',       0.00,     0.133),\n",
    "    ('Payout rate',        'payout_rate',      0.05,     0.08),\n",
    "    ('Expected return \u03bc',  'mu',               0.05,     0.09),\n",
    "    ('Volatility \u03c3',       'sigma',            0.08,     0.18),\n",
    "    ('\u00a77520 rate',         'rate_7520',        0.02,     0.08),\n",
    "]\n",
    "\n",
    "def run_variant(param_field, value):\n",
    "    \"\"\"Run simulation with one parameter changed from baseline.\"\"\"\n",
    "    import copy\n",
    "    from dataclasses import replace\n",
    "    p = replace(baseline, **{param_field: value})\n",
    "    return run_simulation(p)\n",
    "\n",
    "# Run all variants \u2014 this is the main computation for this notebook\n",
    "# Run OAT at BOTH 20% and 60% turnover baselines\n",
    "print('Running OAT sensitivity variants at 20% and 60% baselines...')\n",
    "print(f'  {len(OAT_VARIANTS)} parameters x 2 variants x 2 baselines = {len(OAT_VARIANTS)*4} simulations')\n",
    "print()\n",
    "\n",
    "results_low_20,  results_high_20  = {}, {}\n",
    "results_low_60,  results_high_60  = {}, {}\n",
    "\n",
    "for label, field_name, low_val, high_val in OAT_VARIANTS:\n",
    "    r_lo_20 = run_simulation(replace(baseline_20, **{field_name: low_val}))\n",
    "    r_hi_20 = run_simulation(replace(baseline_20, **{field_name: high_val}))\n",
    "    r_lo_60 = run_simulation(replace(baseline_60, **{field_name: low_val}))\n",
    "    r_hi_60 = run_simulation(replace(baseline_60, **{field_name: high_val}))\n",
    "    results_low_20[label]  = r_lo_20\n",
    "    results_high_20[label] = r_hi_20\n",
    "    results_low_60[label]  = r_lo_60\n",
    "    results_high_60[label] = r_hi_60\n",
    "    print(f'  {label:<28}  '\n",
    "          f'20%: Lo={r_lo_20[\"win_prob\"]:.1%} Hi={r_hi_20[\"win_prob\"]:.1%}  |  '\n",
    "          f'60%: Lo={r_lo_60[\"win_prob\"]:.1%} Hi={r_hi_60[\"win_prob\"]:.1%}')\n",
    "\n",
    "# Convenience aliases \u2014 default to 20% for all individual figures\n",
    "results_low  = results_low_20\n",
    "results_high = results_high_20\n",
    "BASE_WIN = BASE_WIN_20\n",
    "BASE_MED = BASE_MED_20\n",
    "print(f'\\nBaseline 20%: {BASE_WIN_20:.1%} | Baseline 60%: {BASE_WIN_60:.1%}')\n",
    "print('All variants complete.')"
   ],
   "id": "cell-variants"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-markdown-tornado-combined"
   },
   "source": [
    "---\n",
    "## Section 2 \u2014 Tornado Diagrams at 20% and 60% Turnover\n",
    "\n",
    "### Figures 1\u20132: Side-by-Side Tornado \u2014 Median Terminal Net Benefit\n",
    "\n",
    "Displaying the tornado at both 20% (conservative) and 60% (original baseline) turnover levels addresses the reviewer's concern directly: it shows whether the **ranking** of influential parameters changes as turnover changes, not merely the win probability. If the ranking is stable, the sensitivity analysis conclusions are robust to the turnover assumption.\n",
    "\n",
    "**Key question:** Does expected return \u03bc still rank #1 at 20% turnover? Does the \u00a77520 rate still rank last?"
   ],
   "id": "cell-markdown-tornado-combined"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "cell-fig12-tornado",
    "outputId": "c0cc334b-4683-4087-9f69-0da3ffefe8a6"
   },
   "outputs": [],
   "source": [
    "# --- Figures 1-2: Side-by-side tornado diagrams at 20% and 60% turnover ---\n",
    "\n",
    "def draw_tornado(ax, results_lo, results_hi, base_win, base_med, title, metric='median'):\n",
    "    \"\"\"Draw a tornado diagram on ax.\n",
    "    metric: 'median' for net benefit | 'winprob' for win probability\n",
    "    \"\"\"\n",
    "    labels = [v[0] for v in OAT_VARIANTS]\n",
    "    if metric == 'median':\n",
    "        lo_vals = np.array([results_lo[l]['median_delta'] - base_med for l in labels])\n",
    "        hi_vals = np.array([results_hi[l]['median_delta'] - base_med for l in labels])\n",
    "        xlabel  = 'Change in Median Net Benefit vs. Baseline ($000)'\n",
    "        scale   = 1/1000\n",
    "    else:\n",
    "        lo_vals = np.array([results_lo[l]['win_prob'] - base_win for l in labels])\n",
    "        hi_vals = np.array([results_hi[l]['win_prob'] - base_win for l in labels])\n",
    "        xlabel  = 'Change in Win Probability vs. Baseline (pp)'\n",
    "        scale   = 100\n",
    "\n",
    "    rng      = np.abs(hi_vals - lo_vals)\n",
    "    sort_idx = np.argsort(rng)\n",
    "    s_labels = [labels[i] for i in sort_idx]\n",
    "    s_lo     = lo_vals[sort_idx] * scale\n",
    "    s_hi     = hi_vals[sort_idx] * scale\n",
    "    y        = np.arange(len(s_labels))\n",
    "    bar_h    = 0.35\n",
    "\n",
    "    for i, (lo, hi, lbl) in enumerate(zip(s_lo, s_hi, s_labels)):\n",
    "        c_lo = '#d73027' if lo < 0 else '#2171b5'\n",
    "        c_hi = '#d73027' if hi < 0 else '#2171b5'\n",
    "        ax.barh(y[i] + bar_h/2, lo, height=bar_h, color=c_lo, alpha=0.80)\n",
    "        ax.barh(y[i] - bar_h/2, hi, height=bar_h, color=c_hi, alpha=0.45)\n",
    "\n",
    "    ax.axvline(0, color='black', lw=1.5)\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(s_labels, fontsize=9)\n",
    "    ax.set_xlabel(xlabel, fontsize=9)\n",
    "    ax.set_title(title, fontsize=10, fontweight='bold')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7), sharey=False)\n",
    "\n",
    "draw_tornado(axes[0], results_low_20, results_high_20,\n",
    "             BASE_WIN_20, BASE_MED_20,\n",
    "             f'20% Turnover Baseline\\n(win prob = {BASE_WIN_20:.1%})',\n",
    "             metric='median')\n",
    "draw_tornado(axes[1], results_low_60, results_high_60,\n",
    "             BASE_WIN_60, BASE_MED_60,\n",
    "             f'60% Turnover Baseline\\n(win prob = {BASE_WIN_60:.1%})',\n",
    "             metric='median')\n",
    "\n",
    "blue_patch = mpatches.Patch(color='#2171b5', label='Favors CRUT')\n",
    "red_patch  = mpatches.Patch(color='#d73027', label='Favors Benchmark')\n",
    "dark_patch = mpatches.Patch(color='gray', alpha=0.80, label='Low variant')\n",
    "lite_patch = mpatches.Patch(color='gray', alpha=0.45, label='High variant')\n",
    "fig.legend(handles=[blue_patch, red_patch, dark_patch, lite_patch],\n",
    "           fontsize=9, loc='lower center', ncol=4, bbox_to_anchor=(0.5, -0.04))\n",
    "\n",
    "fig.suptitle(\n",
    "    'Figures 1\u20132: Tornado \u2014 Sensitivity of Median Terminal Net Benefit\\n'\n",
    "    'Left = 20% turnover (conservative) | Right = 60% turnover (original baseline)\\n'\n",
    "    'Compare parameter rankings across panels to assess robustness to turnover assumption',\n",
    "    fontsize=11\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig1_2_tornado_side_by_side.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "print('Figures 1-2 saved.')\n",
    "\n",
    "# Print ranking comparison\n",
    "print()\n",
    "print('Parameter ranking comparison (by win probability range):')\n",
    "labels = [v[0] for v in OAT_VARIANTS]\n",
    "ranges_20 = sorted([(abs(results_high_20[l]['win_prob'] - results_low_20[l]['win_prob'])*100, l)\n",
    "                     for l in labels], reverse=True)\n",
    "ranges_60 = sorted([(abs(results_high_60[l]['win_prob'] - results_low_60[l]['win_prob'])*100, l)\n",
    "                     for l in labels], reverse=True)\n",
    "rank_60 = {l: i+1 for i, (_, l) in enumerate(ranges_60)}\n",
    "\n",
    "print(f'{\"Rank\":>5} {\"Parameter (20% baseline)\":<28} {\"Range 20%\":>10} {\"Rank 60%\":>10} {\"Range 60%\":>10}')\n",
    "print('-' * 68)\n",
    "for i, (rng, lbl) in enumerate(ranges_20):\n",
    "    rng60 = next(r for r, l in ranges_60 if l == lbl)\n",
    "    print(f'{i+1:>5} {lbl:<28} {rng:>9.1f}pp {rank_60[lbl]:>10} {rng60:>9.1f}pp')"
   ],
   "id": "cell-fig12-tornado"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-markdown-sweeps"
   },
   "source": [
    "---\n",
    "## Section 3 \u2014 Detailed OAT Sweeps\n",
    "\n",
    "The tornado diagrams provide a single Low/High comparison for each parameter. The following sweeps examine how win probability evolves *continuously* across the full range of each key parameter. This reveals whether effects are linear or exhibit threshold behavior \u2014 information that is obscured by the two-point OAT design.\n",
    "\n",
    "Parameters chosen for detailed sweeps: turnover, fees, expected return, and payout rate. These were selected because they represent **controllable planning variables** \u2014 the planner or client can influence these choices \u2014 as distinct from market or regulatory parameters that are externally determined.\n",
    "\n",
    "**Note on basis and longevity sweeps:** These are the subject of Notebooks 02 and 03 respectively, where they receive more thorough treatment."
   ],
   "id": "cell-markdown-sweeps"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "cell-fig3",
    "outputId": "3b8c0fe1-11df-4225-fefb-acb749e2660d"
   },
   "outputs": [],
   "source": [
    "# --- Figure 3: Portfolio Turnover vs. Win Probability ---\n# The reviewer flagged 60% turnover as high. This sweep shows the full picture\n# from near-passive (10%) through aggressive active (100%).\n\nturnover_vals = np.linspace(0.05, 1.00, 30)\nwp_turnover   = []\nci_turnover   = []\n\nfrom dataclasses import replace\n\nfor tv in turnover_vals:\n    r = run_simulation(replace(baseline, turnover=tv))\n    wp_turnover.append(r['win_prob'])\n    lo, hi = bootstrap_ci(r['delta_wealth'], lambda x: np.mean(x > 0))\n    ci_turnover.append((lo, hi))\n\nwp_turnover = np.array(wp_turnover)\nci_lo_t = np.array([c[0] for c in ci_turnover])\nci_hi_t = np.array([c[1] for c in ci_turnover])\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.fill_between(turnover_vals * 100, ci_lo_t * 100, ci_hi_t * 100,\n                alpha=0.25, color='#2171b5', label='95% bootstrap CI')\nax.plot(turnover_vals * 100, wp_turnover * 100, color='#2171b5', lw=2.5)\nax.axhline(50, color='gray', ls='--', lw=1, label='50% (coin flip)')\nax.axvline(60, color='orange', ls=':', lw=1.5, label='Baseline (60%)')\nax.axvline(20, color='green',  ls=':', lw=1.5, label='Typical index fund (~20%)')\n\nax.set_xlabel('Annual Portfolio Turnover (%)', fontsize=11)\nax.set_ylabel('Win Probability (%)', fontsize=11)\nax.set_title(\n    'Figure 3: Win Probability vs. Benchmark Portfolio Turnover\\n'\n    'All other parameters at baseline | Shaded = 95% bootstrap CI',\n    fontsize=12\n)\nax.legend(fontsize=9)\nax.set_ylim(30, 80)\n\n# Annotation: find crossover point near 50%\ncross_idx = np.argmin(np.abs(wp_turnover - 0.50))\ncross_tv  = turnover_vals[cross_idx] * 100\nax.annotate(f'~50% win at {cross_tv:.0f}% turnover',\n            xy=(cross_tv, 50), xytext=(cross_tv + 8, 40),\n            arrowprops=dict(arrowstyle='->', color='black'),\n            fontsize=9)\n\nplt.tight_layout()\nplt.savefig('fig3_turnover_sweep.png', bbox_inches='tight', dpi=150)\nplt.show()\nprint(f'Figure 3 saved.')\nprint(f'Win probability at 10% turnover: {wp_turnover[0]:.1%}')\nprint(f'Win probability at 60% turnover: {wp_turnover[cross_idx]:.1%}')\nprint(f'Win probability at 100% turnover: {wp_turnover[-1]:.1%}')"
   ],
   "id": "cell-fig3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "cell-fig4",
    "outputId": "c28b0ada-a3a3-4aaf-ae25-12d433dd71e5"
   },
   "outputs": [],
   "source": [
    "# --- Figure 4: Fee Drag vs. Win Probability ---\n# Varies both trust fee and benchmark fee together (assuming fee parity)\n# and separately (trust fee only, benchmark fee only).\n# This reveals whether fee advantage or disadvantage matters more.\n\nfee_vals = np.linspace(0.002, 0.025, 25)\nwp_both, wp_trust_only, wp_bench_only = [], [], []\n\nfor fv in fee_vals:\n    r1 = run_simulation(replace(baseline, trust_fee=fv, bench_fee=fv))\n    r2 = run_simulation(replace(baseline, trust_fee=fv))\n    r3 = run_simulation(replace(baseline, bench_fee=fv))\n    wp_both.append(r1['win_prob'])\n    wp_trust_only.append(r2['win_prob'])\n    wp_bench_only.append(r3['win_prob'])\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(fee_vals * 100, np.array(wp_both)       * 100, color='#2171b5',\n        lw=2.5, label='Both fees move together')\nax.plot(fee_vals * 100, np.array(wp_trust_only) * 100, color='#d73027',\n        lw=2.0, ls='--', label='Trust fee only (benchmark fixed at 1%)')\nax.plot(fee_vals * 100, np.array(wp_bench_only) * 100, color='#238b45',\n        lw=2.0, ls=':', label='Benchmark fee only (trust fixed at 1%)')\nax.axhline(50, color='gray', ls='--', lw=1)\nax.axvline(1.0, color='orange', ls=':', lw=1.5, label='Baseline (1%)')\n\nax.set_xlabel('Annual Fee Rate (%)', fontsize=11)\nax.set_ylabel('Win Probability (%)', fontsize=11)\nax.set_title(\n    'Figure 4: Win Probability vs. Fee Structure\\n'\n    'Shows effect of trust fee, benchmark fee, and both moving together',\n    fontsize=12\n)\nax.legend(fontsize=9)\nax.set_ylim(25, 95)\nplt.tight_layout()\nplt.savefig('fig4_fee_sweep.png', bbox_inches='tight', dpi=150)\nplt.show()\nprint('Figure 4 saved.')"
   ],
   "id": "cell-fig4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4 \u2014 Interpretation\n\n",
    "This figure shows how annual fee rates affect CRUT win probability, with three distinct scenarios:\n\n",
    "**Green dotted line \u2014 Benchmark fee only (trust fixed at 1%):** As the benchmark portfolio becomes more expensive, ",
    "the CRUT wins more often. A costly benchmark is simply easier to beat \u2014 higher fees compound against the benchmark's ",
    "full corpus throughout the horizon.\n\n",
    "**Red dashed line \u2014 Trust fee only (benchmark fixed at 1%):** As the CRUT's own fee rises, win probability falls. ",
    "A more expensive trust bleeds the corpus faster, reducing both distributions and the terminal remainder.\n\n",
    "**Blue solid line \u2014 Both fees move together:** When fees rise symmetrically for both strategies, the CRUT still gains ",
    "ground. This is because fee drag on the benchmark compounds against a larger, fully-invested portfolio, while the CRUT's ",
    "corpus is continuously reduced by the 6% payout \u2014 making the benchmark more sensitive to identical fee increases.\n\n",
    "**The crossing point at 1%** is the baseline \u2014 all three lines converge there by construction. ",
    "The key asymmetry is that the green line (benchmark fee) has a steeper slope than the red dashed line (trust fee): ",
    "benchmark fee increases help the CRUT more than equivalent trust fee increases hurt it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "cell-fig5",
    "outputId": "16970289-c0a9-415a-c11c-bcec61e65a77"
   },
   "outputs": [],
   "source": [
    "# --- Figure 5: Expected Return vs. Win Probability ---\n# Also varies volatility, producing a 2D heatmap.\n\nmu_vals    = np.linspace(0.04, 0.11, 20)\nsigma_vals = np.linspace(0.06, 0.22, 20)\n\n# Line plot: mu sweep at baseline sigma\nwp_mu = [run_simulation(replace(baseline, mu=m))['win_prob'] for m in mu_vals]\n\n# Heatmap: mu x sigma grid\nheatmap = np.zeros((len(sigma_vals), len(mu_vals)))\nfor i, s in enumerate(sigma_vals):\n    for j, m in enumerate(mu_vals):\n        heatmap[i, j] = run_simulation(replace(baseline, mu=m, sigma=s))['win_prob']\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Left: line plot\naxes[0].plot(mu_vals * 100, np.array(wp_mu) * 100, color='#2171b5', lw=2.5)\naxes[0].axhline(50, color='gray', ls='--', lw=1)\naxes[0].axvline(7, color='orange', ls=':', lw=1.5, label='Baseline (7%)')\naxes[0].set_xlabel('Expected Annual Return \u03bc (%)', fontsize=11)\naxes[0].set_ylabel('Win Probability (%)', fontsize=11)\naxes[0].set_title('Win Probability vs. Expected Return\\n(\u03c3 fixed at baseline 12%)', fontsize=11)\naxes[0].legend(fontsize=9)\naxes[0].set_ylim(0, 100)\n\n# Right: heatmap\nim = axes[1].imshow(\n    heatmap * 100, origin='lower', aspect='auto',\n    extent=[mu_vals[0]*100, mu_vals[-1]*100,\n            sigma_vals[0]*100, sigma_vals[-1]*100],\n    cmap='RdYlGn', vmin=20, vmax=80\n)\nplt.colorbar(im, ax=axes[1], label='Win Probability (%)')\naxes[1].scatter([7], [12], color='orange', s=80, zorder=5, label='Baseline')\n# Draw 50% contour\nmu_grid, sigma_grid = np.meshgrid(mu_vals * 100, sigma_vals * 100)\naxes[1].contour(mu_grid, sigma_grid, heatmap * 100, levels=[50],\n                colors='black', linewidths=1.5)\naxes[1].set_xlabel('Expected Annual Return \u03bc (%)', fontsize=11)\naxes[1].set_ylabel('Annual Volatility \u03c3 (%)', fontsize=11)\naxes[1].set_title('Win Probability Heatmap: \u03bc \u00d7 \u03c3\\n(Black line = 50% contour)', fontsize=11)\naxes[1].legend(fontsize=9)\n\nfig.suptitle('Figure 5: Return and Volatility Sensitivity', fontsize=12, y=1.01)\nplt.tight_layout()\nplt.savefig('fig5_return_sweep.png', bbox_inches='tight', dpi=150)\nplt.show()\nprint('Figure 5 saved.')"
   ],
   "id": "cell-fig5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5 \u2014 Interpretation\n\n",
    "**Left panel:** Win probability falls steeply as expected return rises. At low returns (4\u20135%), the CRUT wins ",
    "roughly 90% of the time. At the baseline 7%, it wins ~54%. Above 9%, the benchmark dominates. ",
    "This reflects a structural asymmetry: the CRUT pays out 6% of corpus annually, continuously draining its growth engine, ",
    "while the benchmark compounds unimpeded. At high return assumptions, that compounding advantage overwhelms everything else.\n\n",
    "**Right panel (heatmap):** The 50% contour line (black) is the planning breakeven boundary. ",
    "Points to the left/below the contour are CRUT-favorable (green); to the right/above are benchmark-favorable (red). ",
    "Notably, the contour is nearly vertical \u2014 volatility (\u03c3) has relatively little effect on the breakeven return. ",
    "The sufficient statistic for CRUT viability is primarily the expected return \u03bc, not the Sharpe ratio.\n\n",
    "**Planning implication:** The CRUT is most defensible when the client or advisor holds conservative return expectations. ",
    "If the portfolio is expected to grow at 8%+ annually, the CRUT faces a steep hurdle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "cell-fig6",
    "outputId": "e1c7ad99-cac4-4524-ba42-a7939ff84dba"
   },
   "outputs": [],
   "source": [
    "# --- Figure 6: Payout Rate vs. Win Probability ---\n",
    "# Payout rate affects both the annual income and the trust corpus growth.\n",
    "# Higher payout = more income but faster depletion of corpus.\n",
    "# Must remain compliant with 10% remainder test.\n",
    "\n",
    "payout_vals = np.linspace(0.05, 0.12, 30)\n",
    "wp_payout, compliance_payout = [], []\n",
    "\n",
    "for pv in payout_vals:\n",
    "    r = run_simulation(replace(baseline, payout_rate=pv))\n",
    "    wp_payout.append(r['win_prob'])\n",
    "    compliance_payout.append(r['deduction_res']['compliance'])\n",
    "\n",
    "wp_payout = np.array(wp_payout)\n",
    "compliance_payout = np.array(compliance_payout)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Shade non-compliant region\n",
    "first_noncompliant = payout_vals[~compliance_payout]\n",
    "if len(first_noncompliant) > 0:\n",
    "    nc_threshold = first_noncompliant[0]\n",
    "    ax.axvspan(nc_threshold * 100, payout_vals[-1] * 100,\n",
    "               alpha=0.10, color='red', label='Non-compliant (10% remainder test fails)')\n",
    "\n",
    "ax.plot(payout_vals * 100, wp_payout * 100, color='#2171b5', lw=2.5)\n",
    "ax.axhline(50, color='gray', ls='--', lw=1)\n",
    "ax.axvline(6, color='orange', ls=':', lw=1.5, label='Baseline (6%)')\n",
    "\n",
    "ax.set_xlabel('Stated Annual Payout Rate (%)', fontsize=11)\n",
    "ax.set_ylabel('Win Probability (%)', fontsize=11)\n",
    "ax.set_title(\n",
    "    'Figure 6: Win Probability vs. Payout Rate\\n'\n",
    "    'Red shading = payout rates where 10% remainder test may fail at this \u00a77520 rate',\n",
    "    fontsize=12\n",
    ")\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_ylim(0, 100)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig6_payout_sweep.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "print('Figure 6 saved.')"
   ],
   "id": "cell-fig6"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-markdown-asym"
   },
   "source": [
    "---\n## Section 4 \u2014 Asymmetry Analysis\n\n### Figure 7: Loss Magnitude vs. Gain Magnitude\n\nThe baseline distribution in Notebook 00 (Figure 3) revealed an important asymmetry: when the benchmark wins, it tends to win by more than when the CRUT wins. This is a materially important finding for financial planners \u2014 it means the CRUT's 54.3% win probability may overstate its attractiveness from a risk-adjusted perspective.\n\nThis figure quantifies that asymmetry across all OAT variants, asking: for each parameter setting, what is the median gain when the CRUT wins, versus the median loss when it loses?\n\nA point above the diagonal means the CRUT tends to win big when it wins (favorable); a point below the diagonal means it loses big when it loses (unfavorable). **This chart does not appear in the manuscript and is provided here as an additional diagnostic for practitioners.**"
   ],
   "id": "cell-markdown-asym"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cell-fig7",
    "outputId": "b6e3d320-b280-44e9-a4b4-832ae6da8791"
   },
   "outputs": [],
   "source": [
    "# --- Figure 7: Asymmetry \u2014 median gain vs. median loss magnitude ---\n\ndef gain_loss_stats(delta):\n    \"\"\"Return median gain when CRUT wins, median loss magnitude when it loses.\"\"\"\n    wins  = delta[delta > 0]\n    loses = delta[delta <= 0]\n    med_gain = np.median(wins)  if len(wins)  > 0 else 0\n    med_loss = np.median(np.abs(loses)) if len(loses) > 0 else 0\n    return med_gain, med_loss\n\nall_gains, all_losses, all_labels_asym, all_wps = [], [], [], []\n\n# Baseline\ng, l = gain_loss_stats(base_results['delta_wealth'])\nall_gains.append(g/1000); all_losses.append(l/1000)\nall_labels_asym.append('Baseline'); all_wps.append(BASE_WIN)\n\nfor label, field_name, low_val, high_val in OAT_VARIANTS:\n    for val, suffix in [(low_val, ' (Lo)'), (high_val, ' (Hi)')]:\n        r = run_variant(field_name, val)\n        g, l = gain_loss_stats(r['delta_wealth'])\n        all_gains.append(g/1000); all_losses.append(l/1000)\n        all_labels_asym.append(label + suffix)\n        all_wps.append(r['win_prob'])\n\nall_gains  = np.array(all_gains)\nall_losses = np.array(all_losses)\nall_wps    = np.array(all_wps)\n\nfig, ax = plt.subplots(figsize=(9, 9))\n\nsc = ax.scatter(all_losses, all_gains, c=all_wps * 100,\n                cmap='RdYlGn', s=60, vmin=20, vmax=80, zorder=3)\nplt.colorbar(sc, ax=ax, label='Win Probability (%)')\n\n# Diagonal = symmetric gains/losses\nmax_val = max(all_gains.max(), all_losses.max())\nax.plot([0, max_val], [0, max_val], 'k--', lw=1, label='Symmetric (gain = loss)')\n\n# Label baseline\nax.annotate('Baseline', xy=(all_losses[0], all_gains[0]),\n            xytext=(all_losses[0]+5, all_gains[0]+5), fontsize=8,\n            arrowprops=dict(arrowstyle='->', color='black', lw=0.8))\n\nax.fill_between([0, max_val], [0, max_val], [max_val, max_val],\n                alpha=0.05, color='green', label='Gain > Loss (favorable)')\nax.fill_between([0, max_val], [0, 0], [0, max_val],\n                alpha=0.05, color='red', label='Loss > Gain (unfavorable)')\n\nax.set_xlabel('Median Loss Magnitude When Benchmark Wins ($000)', fontsize=11)\nax.set_ylabel('Median Gain When CRUT Wins ($000)', fontsize=11)\nax.set_title(\n    'Figure 7: Gain/Loss Asymmetry Across OAT Variants\\n'\n    'Points above diagonal = CRUT wins are larger than losses (favorable)\\n'\n    'Color = win probability',\n    fontsize=11\n)\nax.legend(fontsize=9)\nax.set_xlim(0); ax.set_ylim(0)\nplt.tight_layout()\nplt.savefig('fig7_asymmetry.png', bbox_inches='tight', dpi=150)\nplt.show()\nprint('Figure 7 saved.')"
   ],
   "id": "cell-fig7"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-markdown-summary"
   },
   "source": [
    "---\n",
    "## Section 5 \u2014 Summary Table and Findings\n",
    "\n",
    "The table below ranks all OAT variants by their influence on win probability, providing a single reference for the key sensitivity findings. This table supports the manuscript's discussion section."
   ],
   "id": "cell-markdown-summary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cell-summary",
    "outputId": "4b0be119-e84e-4ba4-a6a2-fbe4b5c52d23"
   },
   "outputs": [],
   "source": [
    "# Summary table: all variants ranked by win probability range\n\nprint(f\"{'Parameter':<28} {'Low val':>8} {'WP(Lo)':>8} {'Base':>8} {'WP(Hi)':>8} {'High val':>9} {'Range pp':>9}\")\nprint('-' * 88)\n\nsummary_rows = []\nfor label, field_name, low_val, high_val in OAT_VARIANTS:\n    wp_lo_val = results_low[label]['win_prob']\n    wp_hi_val = results_high[label]['win_prob']\n    rng = abs(wp_hi_val - wp_lo_val) * 100\n    summary_rows.append((rng, label, low_val, high_val, wp_lo_val, wp_hi_val))\n\nsummary_rows.sort(reverse=True)\n\nfor rng, label, low_val, high_val, wp_lo_val, wp_hi_val in summary_rows:\n    # Format low/high value: longevity is in years, others are rates\n    rate_params = {'basis_pct', 'turnover', 'trust_fee', 'bench_fee',\n                   'fed_ordinary', 'fed_ltcg', 'state_rate', 'payout_rate',\n                   'mu', 'sigma', 'rate_7520'}\n    field_name = next(f for l, f, lv, hv in OAT_VARIANTS if l == label)\n    if field_name in rate_params:\n        lo_str = f'{low_val*100:.1f}%'\n        hi_str = f'{high_val*100:.1f}%'\n    else:\n        lo_str = f'{low_val:+.0f} yr'\n        hi_str = f'{high_val:+.0f} yr'\n    print(f\"{label:<28} {lo_str:>9}  {wp_lo_val*100:>6.1f}%  \"\n          f\"{BASE_WIN*100:>6.1f}%  {wp_hi_val*100:>6.1f}%  \"\n          f\"{hi_str:>9}  {rng:>8.1f}pp\")\n\nprint()\nprint('Key findings:')\ntop3 = summary_rows[:3]\nprint(f'  Most influential parameters (by win probability range):')\nfor i, (rng, label, *_) in enumerate(top3):\n    print(f'    {i+1}. {label} ({rng:.1f} pp range)')\nprint()\n\n# Find \u00a77520 rate rank\nfor rank, (rng, label, *_) in enumerate(summary_rows, 1):\n    if '7520' in label:\n        print(f'  \u00a77520 rate ranks #{rank} of {len(summary_rows)} parameters ({rng:.1f} pp range)')\n        print(f'  This confirms the manuscript finding: \u00a77520 rate has limited')\n        print(f'  influence on CRUT economic performance, despite its centrality')\n        print(f'  to deduction compliance under IRC \u00a77520.')\n        break\nprint()\nprint('=' * 88)\nprint('Parameter ranking \u2014 60% turnover baseline (sorted independently)')\nprint('=' * 88)\nprint(f\"{'Parameter':<28} {'Low val':>8} {'WP(Lo)':>8} {'Base':>8} {'WP(Hi)':>8} {'High val':>9} {'Range pp':>9}\")\nprint('-' * 88)\n\nsummary_rows_60 = []\nfor label, field_name, low_val, high_val in OAT_VARIANTS:\n    wp_lo_val = results_low_60[label]['win_prob']\n    wp_hi_val = results_high_60[label]['win_prob']\n    rng = abs(wp_hi_val - wp_lo_val) * 100\n    summary_rows_60.append((rng, label, low_val, high_val, wp_lo_val, wp_hi_val))\n\nsummary_rows_60.sort(reverse=True)\n\nfor rng, label, low_val, high_val, wp_lo_val, wp_hi_val in summary_rows_60:\n    field_name = next(f for l, f, lv, hv in OAT_VARIANTS if l == label)\n    if field_name in rate_params:\n        lo_str = f'{low_val*100:.1f}%'\n        hi_str = f'{high_val*100:.1f}%'\n    else:\n        lo_str = f'{low_val:+.0f} yr'\n        hi_str = f'{high_val:+.0f} yr'\n    print(f\"{label:<28} {lo_str:>9}  {wp_lo_val*100:>6.1f}%  \"\n          f\"{BASE_WIN_60*100:>6.1f}%  {wp_hi_val*100:>6.1f}%  \"\n          f\"{hi_str:>9}  {rng:>8.1f}pp\")\n"
   ],
   "id": "cell-summary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rank-comparison-auto",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# AUTO-GENERATED: Side-by-Side Rank Comparison \u2014 20% vs. 60% Turnover Baseline\n# Depends on summary_rows (20%) and summary_rows_60 (60%) from cell above.\n# Re-running this cell always reflects the current engine results.\n# =============================================================================\n\n# Build lookup: label -> (rank_60, range_60)\nrank60_lookup  = {lbl: (i+1, rng) for i, (rng, lbl, *_) in enumerate(summary_rows_60)}\n\nprint(\"Side-by-Side Rank Comparison: 20% vs. 60% Turnover Baseline\")\nprint()\nprint(\"How to read this table: Each parameter is ranked by its OAT sensitivity\")\nprint(\"range \u2014 the absolute swing in win probability (pp) from Low to High variant,\")\nprint(\"all others held at baseline. Rank shifts show which parameters become more\")\nprint(\"or less decisive as the benchmark grows more tax-inefficient.\")\nprint()\n\nhdr = (f\"{'Rank(20%)':>9}  {'Parameter':<26}  {'Range(20%)':>10}  \"\n       f\"{'Rank(60%)':>9}  {'Range(60%)':>10}  {'Shift':>6}\")\nprint(hdr)\nprint(\"-\" * len(hdr))\n\n# rank60 map for shift arrows\nrank20_map = {lbl: i+1 for i, (_, lbl, *_) in enumerate(summary_rows)}\n\nfor rank20, (rng20, lbl, *_) in enumerate(summary_rows, 1):\n    rank60, rng60 = rank60_lookup[lbl]\n    shift = rank20 - rank60          # positive = moved up (rank number fell)\n    if shift > 0:\n        shift_str = f\"\u2191 {shift}\"\n    elif shift < 0:\n        shift_str = f\"\u2193 {abs(shift)}\"\n    else:\n        shift_str = \"\u2014\"\n    print(f\"{rank20:>9}  {lbl:<26}  {rng20:>9.1f}pp  \"\n          f\"{rank60:>9}  {rng60:>9.1f}pp  {shift_str:>6}\")\n\nprint()\nprint(\"Key observations:\")\ntop_lbl = summary_rows[0][1]\ntop_r20  = summary_rows[0][0]\ntop_r60  = rank60_lookup[top_lbl][1]\nprint(f\"  - {top_lbl} ranks #1 at both baselines \"\n      f\"({top_r20:.1f} pp at 20%, {top_r60:.1f} pp at 60%)\")\n\n# Most rank-shifted parameter (largest absolute shift)\nmax_shift_lbl  = max(summary_rows, key=lambda x: abs(rank20_map[x[1]] - rank60_lookup[x[1]][0]))[1]\ns20 = rank20_map[max_shift_lbl]\ns60 = rank60_lookup[max_shift_lbl][0]\ndirection = \"rises\" if s60 < s20 else \"falls\"\nprint(f\"  - {max_shift_lbl} shows the largest rank shift: \"\n      f\"#{s20} at 20% \u2192 #{s60} at 60% ({direction})\")\n\n# \u00a77520 rate\nfor rng, lbl, *_ in summary_rows:\n    if \"7520\" in lbl:\n        r60 = rank60_lookup[lbl][0]\n        print(f\"  - \u00a77520 rate and Payout rate rank last at both baselines \u2014 \"\n              f\"confirming that these centrally-cited planning parameters \"\n              f\"have minimal economic impact on CRUT performance\")\n        break\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rank60-table-auto",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# AUTO-GENERATED: Full Parameter Ranking \u2014 60% Turnover Baseline\n# Depends on summary_rows_60 computed in cell 20.\n# Re-running this cell always reflects the current engine results.\n# =============================================================================\n\nprint(\"Parameter Ranking \u2014 60% Turnover Baseline\")\nprint()\nprint(\"Each row shows one parameter varied from its Low to High value while\")\nprint(\"all others are held at the 60% turnover baseline. Range is the absolute\")\nprint(\"difference in win probability between the Low and High variant (pp).\")\nprint()\n\nrate_params = {'basis_pct', 'turnover', 'trust_fee', 'bench_fee',\n               'fed_ordinary', 'fed_ltcg', 'state_rate', 'payout_rate',\n               'mu', 'sigma', 'rate_7520'}\n\nhdr = (f\"{'Rank':>5}  {'Parameter':<26}  {'Low val':>9}  \"\n       f\"{'WP(Low)':>8}  {'Base':>7}  {'WP(High)':>9}  \"\n       f\"{'High val':>9}  {'Range':>8}\")\nprint(hdr)\nprint(\"-\" * len(hdr))\n\nfor rank, (rng, lbl, low_val, high_val, wp_lo, wp_hi) in enumerate(summary_rows_60, 1):\n    field_name = next(f for l, f, lv, hv in OAT_VARIANTS if l == lbl)\n    lo_str = f'{low_val*100:.1f}%'  if field_name in rate_params else f'{low_val:+.0f} yr'\n    hi_str = f'{high_val*100:.1f}%' if field_name in rate_params else f'{high_val:+.0f} yr'\n    print(f\"{rank:>5}  {lbl:<26}  {lo_str:>9}  \"\n          f\"{wp_lo*100:>7.1f}%  {BASE_WIN_60*100:>6.1f}%  {wp_hi*100:>8.1f}%  \"\n          f\"{hi_str:>9}  {rng:>7.1f}pp\")\n\nprint()\nprint(f\"Notes:\")\nprint(f\"  Base = {BASE_WIN_60:.1%} win probability at 60% turnover baseline \"\n      f\"(20% turnover baseline = {BASE_WIN_20:.1%})\")\nprint(f\"  Direction matters: for Expected return \u03bc, higher returns hurt the CRUT;\")\nprint(f\"  for Longevity, longer lives help the CRUT.\")\n\n# Highlight \u00a77520\nfor rank, (rng, lbl, *_) in enumerate(summary_rows_60, 1):\n    if \"7520\" in lbl:\n        print(f\"  \u00a77520 rate ranks #{rank} of {len(summary_rows_60)} \"\n              f\"({rng:.1f} pp range) \u2014 confirming minimal economic impact \"\n              f\"despite its centrality to deduction compliance.\")\n        break\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-markdown-decomp"
   },
   "source": "---\n## Section 6 \u2014 Why Does Expected Return Rank #1? A Decomposition\n\nThe sensitivity table above shows expected return \u03bc as the most influential parameter (see auto-generated ranking for current range), with **high returns favoring the benchmark** (win probability falls from 79.1% at \u03bc=5% to 23.8% at \u03bc=9%). This is counterintuitive at first glance \u2014 one might expect a better-performing portfolio to benefit both strategies equally.\n\n### Economic Explanation\n\nThe effect is real and arises from a structural asymmetry between the two strategies:\n\n**The CRUT pays out 6% of the annually revalued corpus each year.** In high-return environments, the corpus grows rapidly \u2014 but so do the mandatory distributions, which leave the trust and are taxed as ordinary income. The *net* corpus remaining in the trust grows more slowly than the benchmark portfolio, which retains and compounds its full value.\n\n**The benchmark benefits disproportionately from high returns** because it compounds on its full corpus. The CRUT's structural tax advantages (deduction benefit, deferred capital gains recognition) are fixed at inception and do not scale with realized market returns. The benchmark's tax friction (turnover drag, LTCG on gains) does scale with returns \u2014 but at high return levels, the gross compounding advantage of the full corpus more than offsets the tax drag.\n\n**At low returns, the CRUT's fixed tax advantages dominate.** When the benchmark is generating modest gross growth, the tax deduction benefit and deferred capital gains recognition represent a larger fraction of total economic value. The benchmark's turnover-driven tax drag remains proportional to (modest) gains, while the CRUT's deduction benefit was computed at inception and is unaffected by subsequent market performance.\n\n**Practical implication for planners:** This finding suggests that CRUT recommendations should be more aggressive in lower-return environments or for clients with conservative portfolios. It also means that the common practitioner assumption \u2014 that CRUTs become more attractive in bull markets because of higher distributions \u2014 is partially incorrect. Higher distributions come at the cost of corpus depletion, and in strong bull markets the benchmark's compounding advantage offsets the CRUT's structural benefits.\n\n**The decomposition figure below** separates the CRUT's economic benefit into three components across the return spectrum, making this mechanism visually explicit.",
   "id": "cell-markdown-decomp"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "id": "cell-fig8",
    "outputId": "5707be58-a612-4d80-e747-1d46e8997767"
   },
   "outputs": [],
   "source": [
    "# --- Figure 8: Return decomposition \u2014 what drives CRUT advantage at different \u03bc? ---\n# Decomposes CRUT personal wealth into:\n#   (A) PV of tax benefit from charitable deduction\n#   (B) PV of after-tax distributions\n# And shows benchmark wealth alongside.\n# This reveals WHY high returns favor the benchmark.\n\nmu_vals_decomp = np.linspace(0.03, 0.12, 25)\npv_tax_benefits, pv_dists, bench_wealths, crut_wealths = [], [], [], []\n\nfor m in mu_vals_decomp:\n    p = replace(baseline, mu=m)\n    ded_res = compute_deduction(\n        fmv=p.fmv, payout_rate=p.payout_rate, rate_7520=p.rate_7520,\n        life_type=p.life_type, age1=p.age1, age2=p.age2,\n        longevity_adj=p.longevity_adj,\n    )\n    T = int(round(ded_res['sim_horizon']))\n    deduction = ded_res['deduction']\n    combined_ordinary = min(p.fed_ordinary, 0.35) + p.state_rate  # OBBBA: deduction benefit capped at 35%\n    annual_agi_limit = p.agi * p.agi_limit_pct\n    remaining = deduction\n    pv_tax = 0.0\n    for yr in range(p.carryforward_years + 1):\n        usable = min(remaining, annual_agi_limit)\n        if usable <= 0:\n            break\n        pv_tax += usable * combined_ordinary / (1 + p.pv_rate) ** yr\n        remaining -= usable\n    returns = generate_return_paths(p.mu, p.sigma, T, p.n_paths, seed=p.seed)\n    tau_ord = p.fed_ordinary + p.state_rate\n    tau_cg  = p.fed_ltcg + p.niit + p.state_rate\n    crut_v = np.full(p.n_paths, p.fmv)\n    dists = np.zeros((p.n_paths, T))\n    for t in range(T):\n        v = crut_v * (1 - p.trust_fee) * returns[:, t]\n        d = v * p.payout_rate\n        dists[:, t] = d * (1 - tau_ord)\n        crut_v = np.maximum(0, v - d)\n    bench_v = np.full(p.n_paths, p.fmv)\n    bench_basis = p.fmv * p.basis_pct\n    for t in range(T):\n        b = bench_v * (1 - p.bench_fee) * returns[:, t]\n        gain = np.maximum(0, b - bench_basis)\n        tax_drag = p.turnover * gain * tau_cg\n        bench_v = np.maximum(0, b - tax_drag)\n        bench_basis = bench_basis + p.turnover * gain * (1 - tau_cg)\n    discount_factors = np.array([(1 + p.pv_rate) ** -(t+1) for t in range(T)])\n    pv_d = (dists * discount_factors[np.newaxis, :]).sum(axis=1)\n    terminal_gain = np.maximum(0, bench_v - bench_basis)\n    bw = (bench_v - terminal_gain * tau_cg) / (1 + p.pv_rate) ** T\n    pv_tax_benefits.append(pv_tax)\n    pv_dists.append(np.mean(pv_d))\n    bench_wealths.append(np.mean(bw))\n    crut_wealths.append(np.mean(pv_d) + pv_tax)\n\npv_tax_benefits = np.array(pv_tax_benefits) / 1000\npv_dists        = np.array(pv_dists)        / 1000\nbench_wealths   = np.array(bench_wealths)   / 1000\ncrut_wealths    = np.array(crut_wealths)    / 1000\nmu_pct = mu_vals_decomp * 100\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Left: stacked area \u2014 CRUT components vs. benchmark\nax = axes[0]\nax.stackplot(mu_pct,\n             [pv_tax_benefits, pv_dists],\n             labels=['Tax benefit (fixed at inception)', 'PV of distributions (grows with \u03bc)'],\n             colors=['#6baed6', '#2171b5'], alpha=0.8)\nax.plot(mu_pct, bench_wealths, color='#d73027', lw=2.5,\n        label='Benchmark wealth (grows faster with \u03bc)')\nax.axvline(7, color='orange', ls=':', lw=1.5, label='Baseline \u03bc=7%')\nax.set_xlabel('Expected Annual Return \u03bc (%)', fontsize=11)\nax.set_ylabel('Mean Present Value ($000)', fontsize=11)\nax.set_title('CRUT Wealth Components vs. Benchmark\\n'\n             'Stacked = CRUT total | Red line = Benchmark', fontsize=11)\nax.legend(fontsize=8, loc='upper left')\n\n# Right: win probability and net benefit vs. mu\nax2 = axes[1]\nnet_benefit = crut_wealths - bench_wealths\ncolor_pos = '#238b45'\ncolor_neg = '#d73027'\nax2.fill_between(mu_pct, 0, net_benefit,\n                 where=net_benefit >= 0, alpha=0.4, color=color_pos,\n                 label='CRUT advantage')\nax2.fill_between(mu_pct, 0, net_benefit,\n                 where=net_benefit < 0, alpha=0.4, color=color_neg,\n                 label='Benchmark advantage')\nax2.plot(mu_pct, net_benefit, color='black', lw=2)\nax2.axhline(0, color='black', lw=1)\nax2.axvline(7, color='orange', ls=':', lw=1.5, label='Baseline \u03bc=7%')\n\n# Find crossover\nsign_changes = np.where(np.diff(np.sign(net_benefit)))[0]\nfor sc in sign_changes:\n    cross_mu = mu_pct[sc]\n    ax2.annotate(f'Crossover\\n~{cross_mu:.1f}%',\n                xy=(cross_mu, 0), xytext=(cross_mu+0.5, net_benefit.max()*0.3),\n                arrowprops=dict(arrowstyle='->', color='black', lw=0.8),\n                fontsize=8)\n\nax2.set_xlabel('Expected Annual Return \u03bc (%)', fontsize=11)\nax2.set_ylabel('Mean Net Benefit: CRUT minus Benchmark ($000)', fontsize=11)\nax2.set_title('Net Economic Advantage by Return Assumption\\n'\n              'Blue = CRUT wins | Red = Benchmark wins', fontsize=11)\nax2.legend(fontsize=9)\n\nfig.suptitle(\n    'Figure 8: Why High Returns Favor the Benchmark\\n'\n    'Tax benefit is fixed at inception; benchmark compounding scales with \u03bc',\n    fontsize=12, y=1.02\n)\nplt.tight_layout()\nplt.savefig('fig8_return_decomposition.png', bbox_inches='tight', dpi=150)\nplt.show()\nprint('Figure 8 saved.')\nprint()\nprint('Key insight: The CRUT tax benefit is computed at inception using the')\nprint('\u00a77520 rate and actuarial tables \u2014 it does not grow with realized returns.')\nprint('The benchmark, by contrast, compounds its full corpus at the realized')\nprint('market rate. At high return assumptions, this compounding advantage')\nprint('outweighs the CRUT structural benefits.')\nprint()\nif len(sign_changes) > 0:\n    print(f'The mean net benefit crossover occurs near \u03bc = {mu_pct[sign_changes[0]]:.1f}%')\n    print(f'Below this return assumption, the CRUT is expected to produce')\n    print(f'greater mean wealth. Above it, the benchmark is expected to dominate.')"
   ],
   "id": "cell-fig8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "cell-fig9",
    "outputId": "b22e521d-1b63-4dd7-de5e-70ead08f6b76"
   },
   "outputs": [],
   "source": [
    "# --- Figure 9: Interaction of expected return and asset basis ---\n# Shows that the return sensitivity depends on basis.\n# At very low basis, high returns still favor CRUT because the deduction\n# is large enough to sustain the advantage even at high growth rates.\n\nmu_grid_vals    = np.linspace(0.04, 0.11, 15)\nbasis_grid_vals = np.linspace(0.05, 0.70, 15)\nheatmap_wb = np.zeros((len(basis_grid_vals), len(mu_grid_vals)))\n\nfor i, b in enumerate(basis_grid_vals):\n    for j, m in enumerate(mu_grid_vals):\n        r = run_simulation(replace(baseline, basis_pct=b, mu=m))\n        heatmap_wb[i, j] = r['win_prob']\n\nfig, ax = plt.subplots(figsize=(10, 7))\nim = ax.imshow(\n    heatmap_wb * 100, origin='lower', aspect='auto',\n    extent=[mu_grid_vals[0]*100, mu_grid_vals[-1]*100,\n            basis_grid_vals[0]*100, basis_grid_vals[-1]*100],\n    cmap='RdYlGn', vmin=10, vmax=90\n)\nplt.colorbar(im, ax=ax, label='Win Probability (%)')\n\n# 50% contour\nmu_g, basis_g = np.meshgrid(mu_grid_vals*100, basis_grid_vals*100)\ncs = ax.contour(mu_g, basis_g, heatmap_wb*100, levels=[50],\n                colors='black', linewidths=2)\nax.clabel(cs, fmt='50%%', fontsize=10)\n\n# Mark baseline\nax.scatter([7], [20], color='orange', s=120, zorder=5,\n           label='Baseline (\u03bc=7%, basis=20%)', edgecolors='black')\n\nax.set_xlabel('Expected Annual Return \u03bc (%)', fontsize=11)\nax.set_ylabel('Asset Basis Fraction (%)', fontsize=11)\nax.set_title(\n    'Figure 9: Win Probability \u2014 Return \u03bc \u00d7 Asset Basis Interaction\\n'\n    'Black contour = 50% | Green = CRUT favored | Red = Benchmark favored\\n'\n    'Reading: for a given basis, how high can returns be before benchmark wins?',\n    fontsize=11\n)\nax.legend(fontsize=9)\nplt.tight_layout()\nplt.savefig('fig9_return_basis_interaction.png', bbox_inches='tight', dpi=150)\nplt.show()\nprint('Figure 9 saved.')\nprint()\nprint('Reading this figure for planners:')\nprint('  - Each row = a client with a specific basis fraction')\nprint('  - Moving right along that row = assuming higher expected returns')\nprint('  - The 50% contour is the breakeven line')\nprint('  - Assets with very low basis remain CRUT-favorable across a wide')\nprint('    range of return assumptions')\nprint('  - As basis rises, only lower return environments favor the CRUT')"
   ],
   "id": "cell-fig9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cell-final",
    "outputId": "f8b1e14b-757d-4e13-a7a6-e619d2a24297"
   },
   "outputs": [],
   "source": [
    "# Final completion check\n",
    "import os\n",
    "figures = [\n",
    "    'fig1_tornado_median.png',\n",
    "    'fig2_tornado_winprob.png',\n",
    "    'fig3_turnover_sweep.png',\n",
    "    'fig4_fee_sweep.png',\n",
    "    'fig5_return_sweep.png',\n",
    "    'fig6_payout_sweep.png',\n",
    "    'fig1_2_tornado_side_by_side.png',\n",
    "    'fig7_asymmetry.png',\n",
    "    'fig8_return_decomposition.png',\n",
    "    'fig9_return_basis_interaction.png',\n",
    "]\n",
    "print('Notebook 01 \u2014 Sensitivity Analysis: completion check')\n",
    "print('-' * 50)\n",
    "for f in figures:\n",
    "    print(f\"  {'OK' if os.path.exists(f) else 'MISSING'} {f}\")\n",
    "print()\n",
    "print(f'Baseline win probability:    {BASE_WIN:.1%}')\n",
    "print(f'Baseline median net benefit: ${BASE_MED:,.0f}')\n",
    "print()\n",
    "print('Notebook 01 (v3) complete. Proceed to Notebook 02 \u2014 Asset Basis.')"
   ],
   "id": "cell-final"
  }
 ]
}
